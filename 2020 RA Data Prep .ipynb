{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(path):\n",
    "    '''\n",
    "    Given a file path with wildcard for extension, capture all filenames.\n",
    "    '''\n",
    "    \n",
    "    file_list = {}\n",
    "    file_list = glob.glob(path)\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agency_short(df):\n",
    "    agency_dict = {'Department of Veterans Affairs': 'VA',\n",
    "                'Department of Labor': 'Labor',\n",
    "                'General Services Administration' : 'GSA',\n",
    "                'Department of Defense': 'DoD',\n",
    "                'US Agency for International Development' : 'USAID',\n",
    "                'Department of State' : 'State',\n",
    "                'Nuclear Regulatory Commission' : 'NRC',\n",
    "                'Department of Homeland Security' : 'DHS',\n",
    "                'Department of Education' : 'ED',\n",
    "                'Department of Justice' : 'DOJ',\n",
    "                'National Science Foundation' : 'NSF',\n",
    "                'Office of Personnel Management' : 'OPM',\n",
    "                'National Aeronautics and Space Administration' : 'NASA',\n",
    "                'Department of Health and Human Services' : 'HHS',\n",
    "                'Environmental Protection Agency' : 'EPA',\n",
    "                'Department of Commerce' : 'DOC',\n",
    "                'Department of Transportation' : 'DOT',\n",
    "                'Social Security Administration' : 'SSA',\n",
    "                'Department of Agriculture' : 'USDA',\n",
    "                'Department of Housing and Urban Development' : 'HUD',\n",
    "                'Department of Energy' : 'DOE',\n",
    "                'Department of the Treasury' : 'Treasury',\n",
    "                'Small Business Administration' : 'SBA',\n",
    "                'Department of the Interior' : 'DOI'}\n",
    "    \n",
    "    df['Agency Short Name'] = df['Agency'].map(agency_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PleaseChoose_clean(df):\n",
    "    PC_dict = {\n",
    "        '[Please Choose]' : 'No Response'}\n",
    "    df = df.replace(PC_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_systems_data(path):\n",
    "    file_list = get_filenames(path)\n",
    "    sheet = \"Part IIA Systems Inventory\"\n",
    "    li = []\n",
    "    for file_name in file_list:\n",
    "        temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "        temp_df['Agency'] = os.path.basename(file_name).split(' - ')[1]\n",
    "        temp_df['Service Area'] = (os.path.basename(file_name.split(' - ')[0])).replace(' Readiness Assessment', '')\n",
    "        try:\n",
    "            temp_df['f) Anticipated Upgrade Date or End of Life'] = pd.to_datetime(temp_df['f) Anticipated Upgrade Date or End of Life'])\n",
    "        except KeyError:\n",
    "            temp_df['f) Anticipated Upgrade Date or End of Life'] = []\n",
    "        temp_df['Anticipated Upgrade Date FY or End of Life FY'] = pd.DatetimeIndex(temp_df['f) Anticipated Upgrade Date or End of Life']).year\n",
    "\n",
    "        li.append(temp_df)\n",
    "        \n",
    "    temp_df = pd.concat(li, axis=0, ignore_index=True, sort=False)\n",
    "    \n",
    "    temp_df['d) Is this a shared system?'] = temp_df['d) Is this a shared system?'].fillna(temp_df['c) Is this a shared system?'])\n",
    "    temp_df['c) Name of Product'] = temp_df['c) Name of Product'].fillna(temp_df['d) Name of Product'])\n",
    "    temp_df = temp_df.drop(['c) Is this a shared system?','d) Name of Product',\n",
    "                           'f) Anticipated Upgrade Date or End of Life'], axis=1)\n",
    "    \n",
    "    temp_df['j) Investment in solution is >$500,000'] = temp_df['j) Investment in solution is >$500,000'].replace('Yes','TRUE')\n",
    "\n",
    "    temp_df = temp_df.rename(index=str, columns={\n",
    "        \"a) Function (Choose from drop-down)\": \"Function\",\n",
    "        \"b) Name of System or Tool\": \"System Name\",\n",
    "        \"d) Is this a shared system?\": \"Shared System (y/n)\",\n",
    "        \"c) Name of Product\": \"Software Name\",\n",
    "        \"e) Version of Product\": \"Version\",\n",
    "        \"g) Age of Current System\": \"System Age\",\n",
    "        \"h) As applicable, UII for CPIC investment\": \"UII or CPIC\",\n",
    "        \"i) As applicable, please add the FY 2018 PIID for any contracts supporting this production instance (services and systems)\": \"2018 PIID\",\n",
    "        \"j) Investment in solution is >$500,000\": \"Investment Greater than $500k\",\n",
    "        \"k) Please rate customer satisfaction with this system (5=Very Satisfied, 1=Very Dissatisfied)\": \"Customer Satisfaction Rating\",\n",
    "        \"l) Would you like to consider an alternative system?\": \"Consider Alternative\"\n",
    "        })\n",
    "    \n",
    "    temp_df = agency_short(temp_df)\n",
    "    temp_df = PleaseChoose_clean(temp_df)\n",
    "        \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "systems_df = get_systems_data(\"data/2019/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    systems_df.to_csv(\"data/2019//Final Data/systems.csv\", encoding = 'utf-8')\n",
    "except FileNotFoundError:\n",
    "    os.makedirs(\"data/2019//Final Data\")\n",
    "    systems_df.to_csv(\"data/2019//Final Data/systems.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_functions_data(path):\n",
    "    file_list = get_filenames(path)\n",
    "    sheet = \"Part IA Functions Activities\"\n",
    "\n",
    "    li = []\n",
    "    for file_name in file_list:\n",
    "        temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "        temp_df['Agency'] = os.path.basename(file_name).split(' - ')[1]\n",
    "        temp_df['Service Area'] = (os.path.basename(file_name.split(' - ')[0])).replace(' Readiness Assessment', '')\n",
    "        temp_df = temp_df.rename(index=str, columns={\n",
    "            \"a) If agency Grants Management staff perform the activity, please provide the count of these staff performing this activity as measured in annual FTE*\": \"Grants Mgmt FTE in Function\",\n",
    "            \"b) If agency Grants Program staff perform the activity, please provide the count of these staff performing the activity as measured in annual FTE*\": \"Grants Program FTE in Function\",\n",
    "            \"c) If an agency Centralized Processing Office performs this activity, please provide the count of staff performing this activity as measured in annual FTE*\": \"Centralized SSP FTE in Function\",\n",
    "            \"d) If a contractor performs the activity, please provide the number of Contract Staff providing this activity as measured in annualized contract staff*\": \"Contractor FTE in Function\",\n",
    "            \"e) If a Centralized Processing Office performs the activity, please provide the names of the organization(s)/office(s) providing processing services.\": \"Centralized SSP Office/Agency\",\n",
    "            \"f) Is this activity standardized? Yes/No\": \"Standardized (y/n)\",\n",
    "            \"g) If this activity is not standardized, please explain.\": \"Reason not Standardized\",\n",
    "            \"h) Would the agency like to consider an outside provider for this activity?\": \"Consider External Provider\"\n",
    "        })\n",
    "        \n",
    "        \n",
    "        temp_df = agency_short(temp_df)\n",
    "        \n",
    "        li.append(temp_df)\n",
    "    \n",
    "    temp_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "    \n",
    "    temp_df = PleaseChoose_clean(temp_df)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_df = get_functions_data(\"data/2019/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_df.to_csv(\"data/2019//Final Data/functions.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_capabilities_data(path):\n",
    "    file_list = get_filenames(path)\n",
    "    sheet = \"Part IB Additional Capabilities\"\n",
    "    li = []\n",
    "    for file_name in file_list:\n",
    "        temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "        temp_df['Agency'] = os.path.basename(file_name).split(' - ')[1]\n",
    "        temp_df['Service Area'] = (os.path.basename(file_name.split(' - ')[0])).replace(' Readiness Assessment', '')\n",
    "        \n",
    "        li.append(temp_df)\n",
    "    \n",
    "    temp_df = pd.concat(li, axis=0, ignore_index=True, sort=False)\n",
    "    temp_df = temp_df.drop(['Agency POC Email','Agency Point of Contact (POC) '], axis=1)\n",
    "    \n",
    "    temp_df = temp_df.rename(index=str, columns={\n",
    "        \"ADDITIONAL Business Capability Statement\": \"Additional Business Capability Statement\",\n",
    "        \"Authoritative Reference for THIS Business Capability Statement (required for must have)\": \"Authoritative Reference for THIS Business Capability Statement\"\n",
    "        })\n",
    "    \n",
    "    temp_df = agency_short(temp_df)\n",
    "    temp_df = PleaseChoose_clean(temp_df)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "capabilities_df = get_capabilities_data(\"data/2019/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "capabilities_df.to_csv(\"data/2019//Final Data/capabilities.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_data(path):\n",
    "    file_list = get_filenames(path)\n",
    "    sheet_list = [\"Part IIB - Readiness for Change\",\n",
    "                 \"Part III Question #2\",\n",
    "                 \"4) Standard Data Definitions\",\n",
    "                 \"Part III Question #1\",\n",
    "                 \"3) Organizational Environment\"]\n",
    "    li = []\n",
    "    for file_name in file_list:\n",
    "        for sheet in sheet_list:\n",
    "            temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "            temp_df['Agency'] = os.path.basename(file_name).split(' - ')[1]\n",
    "            temp_df['Service Area'] = (os.path.basename(file_name.split(' - ')[0])).replace(' Readiness Assessment', '')\n",
    "            temp_df = temp_df.rename(index=str, columns={temp_df.columns[0]: \"Question\",\n",
    "                                                        temp_df.columns[1]: \"Response\",\n",
    "                                                        temp_df.columns[2]: \"Recommendations/Concerns?\"})\n",
    "            \n",
    "            li.append(temp_df)\n",
    "        \n",
    "        li.append(temp_df)\n",
    "    \n",
    "    temp_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "    \n",
    "    temp_df = agency_short(temp_df)\n",
    "    temp_df = PleaseChoose_clean(temp_df)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df =  get_comments_data(\"data/2019/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df = question_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df.to_csv(\"data/2019//Final Data/questions.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments/Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_data(path):\n",
    "    file_list = get_filenames(path)\n",
    "    sheet = \"7) Comments\"\n",
    "    li = []\n",
    "    for file_name in file_list:\n",
    "        temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "        temp_df['Agency'] = os.path.basename(file_name).split(' - ')[1]\n",
    "        temp_df['Service Area'] = (os.path.basename(file_name.split(' - ')[0])).replace(' Readiness Assessment', '')\n",
    "        temp_df['Type'] = 'Comment'\n",
    "        \n",
    "        li.append(temp_df)\n",
    "    \n",
    "    temp_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "    temp_df = temp_df.rename(index=str, columns={\n",
    "        \"7) General Comments\": \"Value\"})\n",
    "    \n",
    "    temp_df = agency_short(temp_df)\n",
    "    temp_df = PleaseChoose_clean(temp_df)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_suggestions_data(path):\n",
    "    file_list = get_filenames(path)\n",
    "    sheet = \"2) Suggestions\"\n",
    "    li = []\n",
    "    for file_name in file_list:\n",
    "        temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "        temp_df['Agency'] = os.path.basename(file_name).split(' - ')[1]\n",
    "        temp_df['Service Area'] = (os.path.basename(file_name.split(' - ')[0])).replace(' Readiness Assessment', '')\n",
    "        temp_df['Type'] = 'Suggestion'\n",
    "        \n",
    "        li.append(temp_df)\n",
    "    \n",
    "    temp_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "    temp_df = temp_df.rename(index=str, columns={\n",
    "        \"2) Do you have any suggestions for improving existing shared grants systems that you use?\": \"Value\"})\n",
    "    \n",
    "    temp_df = agency_short(temp_df)\n",
    "    temp_df = PleaseChoose_clean(temp_df)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = get_comments_data(\"data/2019/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "suggestions_df = get_suggestions_data(\"data/2019/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_df = comments_df.append(suggestions_df)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_df.to_csv(\"data/2019//Final Data/feedback.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pain Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pain_points_data(path):\n",
    "    file_list = get_filenames(path)\n",
    "    sheet = \"5) Pain Points\"\n",
    "    li = []\n",
    "    for file_name in file_list:\n",
    "        temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "        temp_df['Agency'] = os.path.basename(file_name).split(' - ')[1]\n",
    "        temp_df['Service Area'] = (os.path.basename(file_name.split(' - ')[0])).replace(' Readiness Assessment', '')\n",
    "        \n",
    "        li.append(temp_df)\n",
    "    \n",
    "    temp_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "    temp_df = temp_df.rename(index=str, columns={\n",
    "        \"Pain Points\": \"Pain Point\"})\n",
    "    \n",
    "    temp_df = agency_short(temp_df)\n",
    "    temp_df = PleaseChoose_clean(temp_df)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_df = get_pain_points_data(\"data/2019/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_df.to_csv(\"data/2019//Final Data/pain points.csv\", encoding = 'utf-8')\n",
    "\n",
    "try:\n",
    "    capabilities_df.to_csv(\"data/2019//Final Data/capabilities.csv\", encoding = 'utf-8')\n",
    "except FileNotFoundError:\n",
    "    os.makedirs(\"data/2019//Final Data\")\n",
    "    capabilities_df.to_csv(\"data/2019//Final Data/capabilities.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Impediments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_policy_imped_data(path):\n",
    "    file_list = get_filenames(path)\n",
    "    sheet = \"6) Policy Impediments\"\n",
    "    li = []\n",
    "    for file_name in file_list:\n",
    "        temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "        temp_df['Agency'] = os.path.basename(file_name).split(' - ')[1]\n",
    "        temp_df['Service Area'] = (os.path.basename(file_name.split(' - ')[0])).replace(' Readiness Assessment', '')\n",
    "        \n",
    "        li.append(temp_df)\n",
    "    \n",
    "    temp_df = pd.concat(li, axis=0, ignore_index=True, sort=False)\n",
    "    temp_df = temp_df.rename(index=str, columns={\n",
    "        \"Name of Policy\": \"Policy Name\",\n",
    "        \"Choose from drop downs below\": \"Impediment Type\"})\n",
    "    temp_df = temp_df.drop(['6) If applicable, please provide details of any statute, regulation or policy impeding the further adoption, standardization, or consolidation including name, type, and any additional relevant information.'], axis=1)\n",
    "    \n",
    "    temp_df = agency_short(temp_df)\n",
    "    temp_df = PleaseChoose_clean(temp_df)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_df = get_policy_imped_data(\"data/2019/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_df.to_csv(\"data/2019//Final Data/policy impediments.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_cap_ratio(df):\n",
    "    #denominator is total number of Activities for Grants Management (15) \n",
    "    y_denominator = 15\n",
    "    try:\n",
    "        y_numerator = df['Must Have/Nice to Have'].value_counts().loc['Must Have']\n",
    "    except KeyError:\n",
    "        y_numerator = 0\n",
    "    \n",
    "    try: \n",
    "        standard_capabilities_ratio = float(y_numerator) / y_denominator\n",
    "    except ZeroDivisionError:\n",
    "        standard_capabilities_ratio = None\n",
    "    \n",
    "    return standard_capabilities_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_req_cap(df):\n",
    "    try:\n",
    "        req_cap = df['Must Have/Nice to Have'].value_counts().loc['Must Have']\n",
    "    except KeyError:\n",
    "        req_cap = None\n",
    "    \n",
    "    return req_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization_score(row):\n",
    "    if row['f) Is this activity standardized? Yes/No'] == 'Yes':\n",
    "        return 100\n",
    "    if row['f) Is this activity standardized? Yes/No'] == 'No':\n",
    "        return 0\n",
    "    if row['f) Is this activity standardized? Yes/No'] == 'In Part':\n",
    "        return 50\n",
    "    else:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stand_score_calc(file_name):\n",
    "    \n",
    "    sheet = \"Part IA Functions Activities\"\n",
    "    temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "    temp_df['Standardization Score'] = temp_df.apply (lambda row: standardization_score(row), axis=1)\n",
    "    \n",
    "    from pandas.core.groupby.groupby import DataError\n",
    "    try:\n",
    "        weighted_std_score = temp_df.groupby(by = ['Activity', 'Function'])['Standardization Score'].mean().mean()\n",
    "    except DataError:\n",
    "        weighted_std_score = None \n",
    "\n",
    "    return weighted_std_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_data(path):\n",
    "    file_list = get_filenames(path)\n",
    "    sheet = \"Part IB Additional Capabilities\"\n",
    "    li = []\n",
    "    for file_name in file_list:\n",
    "        temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "        agency = os.path.basename(file_name).split(' - ')[1]\n",
    "        service_area = (os.path.basename(file_name.split(' - ')[0])).replace(' Readiness Assessment', '')\n",
    "        standard_capabilities_ratio = std_cap_ratio(temp_df)\n",
    "        req_cap = num_req_cap(temp_df)\n",
    "        stand_score = stand_score_calc(file_name)\n",
    "        try:\n",
    "            stand_factor = (standard_capabilities_ratio)/2 + (stand_score)/2\n",
    "        except TypeError:\n",
    "            stand_factor = None\n",
    "        \n",
    "        d = {'Agency': [agency], \n",
    "             'Service Area': [service_area],\n",
    "             'Standardized Factor': [stand_factor],\n",
    "             'Number of Required Capabilities': [req_cap],\n",
    "             'Standard Capabilities Ratio': [standard_capabilities_ratio],\n",
    "             'Inter-Agency Aligment': [stand_score]}\n",
    "        temp_df = pd.DataFrame(data = d)\n",
    "        temp_df = pd.melt(temp_df, id_vars = ['Agency', 'Service Area'], \n",
    "        value_vars=['Inter-Agency Aligment', 'Number of Required Capabilities','Standard Capabilities Ratio' ,'Standardized Factor'], \n",
    "        var_name='Variable', value_name='Value')\n",
    "        \n",
    "        li.append(temp_df)\n",
    "        \n",
    "    temp_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "    \n",
    "    temp_df = agency_short(temp_df)\n",
    "    temp_df = PleaseChoose_clean(temp_df)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = get_metrics_data(\"data/2019/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(\"data/2019//Final Data/metrics.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standardization_data(path):\n",
    "    file_list = get_filenames(path)\n",
    "    sheet = \"Part IA Functions Activities\"\n",
    "    li = []\n",
    "    for file_name in file_list:\n",
    "        temp_df = pd.read_excel(file_name, sheet_name = sheet)\n",
    "        temp_df['Agency'] = os.path.basename(file_name).split(' - ')[1]\n",
    "        temp_df['Service Area'] = (os.path.basename(file_name.split(' - ')[0])).replace(' Readiness Assessment', '')\n",
    "        temp_df['Standardization Score'] = temp_df.apply (lambda row: standardization_score(row), axis=1)\n",
    "        temp_df = temp_df[['Agency','Service Area','Function', 'Activity','Standardization Score']]\n",
    "        \n",
    "        li.append(temp_df)\n",
    "        \n",
    "    temp_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "    \n",
    "    temp_df = agency_short(temp_df)\n",
    "    temp_df = PleaseChoose_clean(temp_df)\n",
    "    \n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization_df = get_standardization_data(\"data/2019/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization_df.to_csv(\"data/2019//Final Data/standardization.csv\", encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
